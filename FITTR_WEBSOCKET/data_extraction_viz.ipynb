{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\capstone\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from g_media_pipe import extract_data_from_video, list_files_in_directory, process_and_save_mp4_to_csv\n",
    "import ast\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.curdir\n",
    "mp4_directory = os.path.join(directory,\"datasets\")\n",
    "BICEP_CURLS_MP4 = os.path.join(mp4_directory,\"Bicep_Curls\")\n",
    "PROPER_BICEP_CURLS_MP4 = os.path.join(BICEP_CURLS_MP4,\"Proper\")\n",
    "IMPROPER_BICEP_CURLS_MP4 = os.path.join(BICEP_CURLS_MP4,\"Improper\")\n",
    "proper_mp4_list = list_files_in_directory(PROPER_BICEP_CURLS_MP4)\n",
    "improper_mp4_list = list_files_in_directory(IMPROPER_BICEP_CURLS_MP4)\n",
    "\n",
    "proper_output_csv_directory = os.path.join(directory,\"model_data\",\"Bicep_curls\",\"Proper\")\n",
    "improper_output_csv_directory = os.path.join(directory,\"model_data\",\"Bicep_curls\",\"Improper\")\n",
    "assert os.path.exists(proper_output_csv_directory) and os.path.exists(improper_output_csv_directory), \"Proper check: {} Improper check: {}\".format(os.path.exists(proper_output_csv_directory),os.path.exists(improper_output_csv_directory))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 9 .mp4 files\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\dumbellFront.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\capstone\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved csv file: 1/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\dumbellSide.mp4\n",
      "Saved csv file: 2/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_1.mp4\n",
      "Saved csv file: 3/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_2.mp4\n",
      "Saved csv file: 4/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_3.mp4\n",
      "Saved csv file: 5/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_4.mp4\n",
      "Saved csv file: 6/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_5.mp4\n",
      "Saved csv file: 7/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_6.mp4\n",
      "Saved csv file: 8/9 to .\\model_data\\Bicep_curls\\Proper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Proper\\g1_bicepcurl_7.mp4\n",
      "Saved csv file: 9/9 to .\\model_data\\Bicep_curls\\Proper\n"
     ]
    }
   ],
   "source": [
    "process_and_save_mp4_to_csv(proper_mp4_list,proper_output_csv_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 15 .mp4 files\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b1_bicepcurl_1.mp4\n",
      "Saved csv file: 1/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b1_bicepcurl_2.mp4\n",
      "Saved csv file: 2/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b1_bicepcurl_3.mp4\n",
      "Saved csv file: 3/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b1_bicepcurl_4.mp4\n",
      "Saved csv file: 4/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b2_bicepcurl_1.mp4\n",
      "Saved csv file: 5/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b2_bicepcurl_2.mp4\n",
      "Saved csv file: 6/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b3_bicepcurl_2.mp4\n",
      "Saved csv file: 7/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b3_bicepcurl_3.mp4\n",
      "Saved csv file: 8/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b4_bicepcurl_1.mp4\n",
      "Saved csv file: 9/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b4_bicepcurl_2.mp4\n",
      "Saved csv file: 10/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b5_bicepcurl_1.mp4\n",
      "Saved csv file: 11/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b5_bicepcurl_2.mp4\n",
      "Saved csv file: 12/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b5_bicepcurl_3.mp4\n",
      "Saved csv file: 13/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b6_bicepcurl_1.mp4\n",
      "Saved csv file: 14/15 to .\\model_data\\Bicep_curls\\Improper\n",
      "Extracting data from video file: .\\datasets\\Bicep_Curls\\Improper\\b6_bicepcurl_2.mp4\n",
      "Saved csv file: 15/15 to .\\model_data\\Bicep_curls\\Improper\n"
     ]
    }
   ],
   "source": [
    "process_and_save_mp4_to_csv(improper_mp4_list,improper_output_csv_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoProcessingPipeline: \n",
    "    \"\"\"\n",
    "    Class for identifying the number of squats done in a .mp4 video\n",
    "    \"\"\"\n",
    "    def __init__(self,video_file_path:str,threshold:float = 0.25) -> None:\n",
    "        self.threshold = threshold\n",
    "        raw_data = extract_data_from_video(video_path=video_file_path)\n",
    "        df = pd.DataFrame(raw_data).drop(['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER',\n",
    "       'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER', 'LEFT_EAR',\n",
    "       'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER',\n",
    "       'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST',\n",
    "       'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX','LEFT_THUMB', 'RIGHT_THUMB','LEFT_ANKLE', 'RIGHT_ANKLE', 'LEFT_HEEL', 'RIGHT_HEEL',\n",
    "       'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'],axis=1)\n",
    "        processed_df = self.process_df(df)\n",
    "        for col in processed_df.columns:\n",
    "            processed_df[col] = self.smooth_gaussian(self.min_max_scaler(processed_df[col]))\n",
    "        self.data = processed_df\n",
    "        \n",
    "    def process_df(self,data:pd.DataFrame) -> pd.DataFrame:\n",
    "        if isinstance(data.iloc[0][0],str):\n",
    "            data = data.map(ast.literal_eval)\n",
    "\n",
    "        x_coors = data.map(lambda coords: coords[0])  # Get the X coordinates\n",
    "        y_coors = data.map(lambda coords: coords[1])  # Get the Y coordinates\n",
    "        z_coors = data.map(lambda coords: coords[2])  # Get the Z coordinates\n",
    "\n",
    "        # If you want to combine these into a single DataFrame with columns like NOSE_x, NOSE_y, NOSE_z, etc.\n",
    "        x_coors.columns = [f'{col}_x' for col in x_coors.columns]\n",
    "        y_coors.columns = [f'{col}_y' for col in y_coors.columns]\n",
    "        z_coors.columns = [f'{col}_z' for col in z_coors.columns]\n",
    "        # Combine the x, y, z data into a single DataFrame\n",
    "        return pd.concat([x_coors, y_coors, z_coors], axis=1)\n",
    "    \n",
    "    def min_max_scaler(self,col:pd.Series)->pd.Series:\n",
    "        min_value = np.min(col)\n",
    "        max_value = np.max(col)\n",
    "        return col.map(lambda x: (x-min_value)/(max_value-min_value))\n",
    "    \n",
    "    def smooth_gaussian(self,data:pd.Series, sigma=2)->pd.Series:\n",
    "        \"\"\"\n",
    "        Smoothen the curves using a Gaussian filter.\n",
    "\n",
    "        Parameters:\n",
    "        - data: NumPy array, the input signal to smooth.\n",
    "        - sigma: Standard deviation of the Gaussian kernel.\n",
    "\n",
    "        Returns:\n",
    "        - smoothed_data: NumPy array of the smoothed data.\n",
    "        \"\"\"\n",
    "        kernel_radius = int(3 * sigma)  # 3 standard deviations cover ~99% of data\n",
    "        x = np.arange(-kernel_radius, kernel_radius + 1)\n",
    "        gaussian_kernel = np.exp(-x**2 / (2 * sigma**2))\n",
    "        gaussian_kernel /= gaussian_kernel.sum()  # Normalize the kernel\n",
    "        \n",
    "        # Padding to avoid edge effects\n",
    "        padded_data = np.pad(data, pad_width=kernel_radius, mode='edge')\n",
    "        \n",
    "        # Convolution with Gaussian kernel\n",
    "        smoothed_data = np.convolve(padded_data, gaussian_kernel, mode='valid')\n",
    "        \n",
    "        return smoothed_data\n",
    "    \n",
    "    def count_reps(self):\n",
    "        left_knee_count = right_knee_count = 0\n",
    "        right_knee_col = self.data['RIGHT_KNEE_z']\n",
    "        left_knee_col = self.data['LEFT_KNEE_z']\n",
    "        for i in range(len(right_knee_col)-1):\n",
    "            if right_knee_col[i] > self.threshold and right_knee_col[i+1] <= self.threshold:\n",
    "                right_knee_count += 1\n",
    "            if left_knee_col[i] > self.threshold and left_knee_col[i+1] <= self.threshold:\n",
    "                left_knee_count += 1\n",
    "        return (left_knee_count,right_knee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a new mp4 file and count the number of reps\n",
    "#pipeline = VideoProcessingPipeline(r\"D:\\NirwanaWarehouse\\uniWork\\Term 7\\Capstone\\backend\\FITTR_WEBSOCKET\\datasets\\Test\\Exercise Library_ Squats_8_reps.mp4\")\n",
    "#save_data(videoData=video_data,output_path=r\"D:\\NirwanaWarehouse\\uniWork\\Term 7\\Capstone\\backend\\datasets\\Test\\Squats_8_reps.csv\")\n",
    "# pipeline = extract_data_from_video()\n",
    "# pipeline = pd.DataFrame.from_dict(pipeline)\n",
    "# pipeline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define joint groups for left side (similar logic applies to right side)\n",
    "left_knee_angle_joints = (\"LEFT_HIP\", \"LEFT_KNEE\", \"LEFT_ANKLE\")\n",
    "left_hip_angle_joints = (\"LEFT_SHOULDER\", \"LEFT_HIP\", \"LEFT_KNEE\")\n",
    "#left_ankle_angle_joints = (\"LEFT_KNEE\", \"LEFT_ANKLE\", \"LEFT_FOOT_INDEX\")\n",
    "\n",
    "right_knee_angle_joints = (\"RIGHT_HIP\", \"RIGHT_KNEE\", \"RIGHT_ANKLE\")\n",
    "right_hip_angle_joints = (\"RIGHT_SHOULDER\", \"RIGHT_HIP\", \"RIGHT_KNEE\")\n",
    "#right_ankle_angle_joints = (\"RIGHT_KNEE\", \"RIGHT_ANKLE\", \"RIGHT_FOOT_INDEX\")\n",
    "\n",
    "def euclidean(joint1,joint2):\n",
    "        joint1 = eval(joint1)\n",
    "        joint2 = eval(joint2)\n",
    "        xi,yi,zi = joint1\n",
    "        xj,yj,zj = joint2\n",
    "        return (np.square(xi-xj)+np.square(yi-yj)+np.square(zi-zj))**0.5\n",
    "\n",
    "def calculate_joint_angle(a,b,c):\n",
    "    \"\"\"\n",
    "    Computes 3D joint angle inferred by 3 keypoints and their relative positions to one another\n",
    "    \n",
    "    \"\"\"\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "def smooth_gaussian(data:pd.Series, sigma=2)->pd.Series:\n",
    "    \"\"\"\n",
    "    Smoothen the curves using a Gaussian filter.\n",
    "    Parameters:\n",
    "    - data: NumPy array, the input signal to smooth.\n",
    "    - sigma: Standard deviation of the Gaussian kernel.\n",
    "    Returns:\n",
    "    - smoothed_data: NumPy array of the smoothed data.\n",
    "    \"\"\"\n",
    "    kernel_radius = int(3 * sigma)  # 3 standard deviations cover ~99% of data\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)\n",
    "    gaussian_kernel = np.exp(-x**2 / (2 * sigma**2))\n",
    "    gaussian_kernel /= gaussian_kernel.sum()  # Normalize the kernel\n",
    "    \n",
    "    # Padding to avoid edge effects\n",
    "    padded_data = np.pad(data, pad_width=kernel_radius, mode='edge')\n",
    "    \n",
    "    # Convolution with Gaussian kernel\n",
    "    smoothed_data = np.convolve(padded_data, gaussian_kernel, mode='valid')\n",
    "    \n",
    "    return pd.Series(smoothed_data,index=data.index)\n",
    "\n",
    "def calculate_angle(joint_a, joint_b, joint_c):\n",
    "    \"\"\"\n",
    "    Calculate the angle between three joints in 3D space using numpy.\n",
    "    \n",
    "    Args:\n",
    "    joint_a (tuple): The (x, y, z) coordinates of the first joint.\n",
    "    joint_b (tuple): The (x, y, z) coordinates of the second joint (vertex joint).\n",
    "    joint_c (tuple): The (x, y, z) coordinates of the third joint.\n",
    "    \n",
    "    Returns:\n",
    "    float: The angle in degrees between the three joints.\n",
    "    \"\"\"\n",
    "    # Convert joint coordinates to numpy arrays\n",
    "    joint_a = np.array(joint_a, dtype=float)\n",
    "    joint_b = np.array(joint_b, dtype=float)\n",
    "    joint_c = np.array(joint_c, dtype=float)\n",
    "\n",
    "\n",
    "    # Calculate vectors: Joint A to B and Joint B to C\n",
    "    vector_ab = joint_b - joint_a\n",
    "    vector_bc = joint_c - joint_b\n",
    "    \n",
    "    # Calculate dot product and magnitudes using numpy\n",
    "    dot_product = np.dot(vector_ab, vector_bc)\n",
    "    magnitude_ab = np.linalg.norm(vector_ab)\n",
    "    magnitude_bc = np.linalg.norm(vector_bc)\n",
    "    \n",
    "    # Avoid division by zero by ensuring valid magnitude values\n",
    "    if magnitude_ab == 0 or magnitude_bc == 0:\n",
    "        raise ValueError(\"One of the vectors has zero length, can't calculate angle.\")\n",
    "    \n",
    "    # Calculate the cosine of the angle\n",
    "    cos_theta = dot_product / (magnitude_ab * magnitude_bc)\n",
    "    \n",
    "    # Ensure cos_theta is within [-1, 1] to avoid domain errors\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    \n",
    "    # Calculate the angle in radians, then convert to degrees\n",
    "    angle_rad = np.arccos(cos_theta)\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    return angle_deg\n",
    "\n",
    "def joint_angles_per_record(record, joints):\n",
    "    \"\"\"\n",
    "    Calculate the joint angle for a single record (pd.Series).\n",
    "    \n",
    "    Args:\n",
    "    record (pd.Series): A single row from a DataFrame containing joint positions.\n",
    "    joints (list): List of three joint names as strings (column names).\n",
    "    \n",
    "    Returns:\n",
    "    float: The calculated angle for the given joints in the record.\n",
    "    \"\"\"\n",
    "    joint_a, joint_b, joint_c = joints\n",
    "\n",
    "    # Extract joint coordinates directly from the record\n",
    "    a_coords = record[joint_a]\n",
    "    b_coords = record[joint_b]\n",
    "    c_coords = record[joint_c]\n",
    "    \n",
    "    # Convert string of coordinates to tuple (x, y, z) if necessary\n",
    "    if isinstance(a_coords, (list, tuple)):\n",
    "        pass  # already in (x, y, z) format\n",
    "    if isinstance(a_coords,str):\n",
    "        a_coords = ast.literal_eval(a_coords)\n",
    "        b_coords = ast.literal_eval(b_coords)\n",
    "        c_coords = ast.literal_eval(c_coords)\n",
    "    else:\n",
    "        a_coords = tuple(a_coords)\n",
    "        b_coords = tuple(b_coords)\n",
    "        c_coords = tuple(c_coords)\n",
    "    # Calculate the angle between the joints\n",
    "    angle = calculate_angle(a_coords, b_coords, c_coords)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "def plot_joint_angles(df, joints, angle_name=\"Angle\"):\n",
    "    \"\"\"\n",
    "    Calculate and plot joint angles over time.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): DataFrame containing joint positions for each timeframe.\n",
    "    joints (list): List of three joints as tuples of (x, y, z) columns.\n",
    "    angle_name (str): Name for the angle being calculated.\n",
    "    \"\"\"\n",
    "    joint_a, joint_b, joint_c = joints\n",
    "    \n",
    "    # Initialize an empty list to store the angles\n",
    "    angles = []\n",
    "    \n",
    "    # Iterate over each row (timeframe) in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract joint coordinates\n",
    "        a_coords = row[joint_a]\n",
    "        b_coords = row[joint_b]\n",
    "        c_coords = row[joint_c]\n",
    "        if isinstance(a_coords,str):\n",
    "            a_coords = ast.literal_eval(a_coords)\n",
    "            b_coords = ast.literal_eval(b_coords)\n",
    "            c_coords = ast.literal_eval(c_coords)\n",
    "        # Calculate angle and append to list\n",
    "        angle = calculate_angle(a_coords, b_coords, c_coords)\n",
    "        angles.append(angle)\n",
    "    angles = smooth_gaussian(pd.Series(angles))\n",
    "    \n",
    "    # Plot the angles over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df.index, angles, label=f'{angle_name}')\n",
    "    plt.xlabel(\"Timeframe\")\n",
    "    plt.ylabel(\"Angle (degrees)\")\n",
    "    plt.title(f'{angle_name} Over Time')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
